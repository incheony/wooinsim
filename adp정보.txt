https://cafe.naver.com/datageeks?iframe_url=/ArticleList.nhn%3Fsearch.clubid=26910945%26search.menuid=91
https://cafe.naver.com/datageeks/1255
https://calebpro.tistory.com/553
https://ckmoong.tistory.com/category/Work/ADP?page=2
https://ckmoong.tistory.com/7?category=933194
https://gorakgarak.tistory.com/1300
https://shiningyouandme.tistory.com/7
https://didalsgur.tistory.com/70
https://ysyblog.tistory.com/114
https://didalsgur.tistory.com/25?category=750762
https://m.blog.naver.com/sinrakr/222185635683





[1] 데이터 불러오기

[2] 데이터 탐색
(1) 데이터 결측치 찾기
(2) 빈값, 음수면 안되는데 음수인 값은 NA로 넣어주기
(3) 데이터 타입 변경하기
(4) 변수 분포 확인하기
값의 범위가 극단적이면 정규화
분포가 극단적이면 로그 변환
(5) 연속형 자료 이상치 핸들링
dbscan 함수
(6) 변수 별 빈도수가 유독 적으면 upsampling
(7) 선형모형 적합시 독립변수 간 상관관계 없도록 처리
다중공선성 높은 변수 제거
주성분 분석 시행

[회귀분석R]
https://rstudio-pubs-static.s3.amazonaws.com/190997_40fa09db8e344b19b14a687ea5de914b.html

================================================

[[01회]] 2014.06.28

================================================

[[11회]] 2018.10.
https://0dood0.tistory.com/35?category=1012731
  
1. 통계학 기반 분석
2. Text Mining을 적용한 분석
3. Data mining(ML) 학습을 통한 결과 도출 


1. 통계학 기반 분석 (40점)
- 각 설명변수들과 출산률(종속변수)의 관계를 회귀분석으로 정의 및 결과를 해석하는 문제  

2. Text mining (20점)
- 영화평 Data를 전처리 후, '형용사'를 추출 하여 감성 분석 하는 문제
사실 R을 활용한 Text Mining 대부분의 예시는 '명사'를 추출하는 형태로 되어 있고, 명사 추출은 extractNoun 함수로 쉽게 수행을 할 수 있다.
그런데 형용사 같은 경우는.... SimplePos22 함수를 써야하는데 해당 부분을 제대로 숙지하지 못하고 가서, 결국 for문을 만들다 시간이 부족해 실패를 해버린 것이다.

3. Data Mining/ML (40점)
- (R을 공부하는 많은 사람들이 익숙한) 타이타닉 생존자 Data를 Data mining 학습하여, 생존여부 예측을 하는 문제 
- 금번회차의 경우 분석 과정은 상관없고,  오직 제공된 Test Data의 정답만을 제출해서, 예측한 정답의 적중률이 얼마나 높은지로 채점을 함

================================================

[[14회]]
출처: https://didalsgur.tistory.com/32 [Took-Took]

기계 학습을 이용하여 집 가격 예측 및 검증
다중 로지스틱 회귀 분석 및 confusion matrix 해석



================================================

[[15회]]
https://0dood0.tistory.com/64?category=1012731

1번은 무슨 제철회사 Iot data 같은 것들을 제공해 주고,
- EDA(탐색적 데이터 분석) 해보는 거
- 독립변수 선별 (feature engineering)
- 종속변수(y)를 이항으로 바꾸고 로지스틱 회귀 분석하기
- 종속변수(y) 다항인 상태에서 SVM 포함하여 3가지 알고리즘으로 돌려보고 평가
- 위에서 만든 모델 중 하나 적합한 모형 찾아서 군집분석 실시하고 군집분석을 반영하여 F1 score값을 통해 
모델이 나아지는지 확인과 같은 것을 진행하는 것이다.

1번문제도 기존 11회 실기의 머신러닝 문제와 비교해 나름 난이도가 낮은 편은 아니었지만, 
그나마 손을 댈 수는 있었는데, 솔직히 군집분석을 기존 머신러닝 결과에 반영하라는게 무슨 의미인지 몰라서,
좀 벙찌기도 했었다.
(나중에 카페 글을 보니 해당 군집을 또 독립변수로 놓고 학습을 하면 모델의 질이 높아질 수 있다. 뭐 그런 뜻인 것 같다. 솔직히 이와 같은 분석 방식을 난 전혀 모르고 있었다)

2번은.. 전력사용량 관련 data를 제공해주었는데
그 망할 timestamp라는 무슨 열 몇자리 숫자로 구성된 데이터가 나와서,
이걸 어떻게 변환하지? 머리가 새하얗게 변하면서 그냥 망해버렸다.
가장 기본이 되는 시계열 column (3개의 data의 key가 되어야 하는 column이었음) 을 변환을 못하니 뭐 그냥 문제 자체에 손을 못대고 넋을 놓게되어 버렸다.

솔직히 2번문제 접하고 나서,  와... 이건 내가 이 Data형을 실무에서 경험하지 못했다면, 
아무리 공부를 많이 했어도, 책을 3~4권 더 봤어도 이걸 풀 수 있었을까? 라는 생각이 들면서
마음속 깊이, 내 자질을 의심했다. 

이것도 알고보니 python 함수하나로 간단히 해결되는 문제인데,  뭐 내가 이런걸 봤어야지 .ㅠ
(datatime package안에 fromtimestamp 뭐이런 함수가 있음... 열라 간단...)

사실 내가 참고한 python 데이터 분석 관련 책, R 책에는 정말 조금이라도 비슷한 유형이 하나도 나오지 않아.. 
정말 당황스러운 시간이었다..

================================================
[[17회]] 2020.06.21
https://bigdata-analyst.tistory.com/m/34?category=825660
https://0dood0.tistory.com/150
https://statinknu.tistory.com/19


Q1) ML
Housing data (not california housing but temp)
데이터 컬림이 약간 다른 것 빼고는 비슷함.
특히 log1p로 정규화시키는 것도 비슷.

1.1) EDA, PreProcessing (5점)


1. 주택가격 예측을 위한 ML 모델 생성/평가
- 여러 설명변수들로 Price (수치형 종속변수) 를 예측하는 모델을 만드는 문제였음
- 집값에 영향을 미칠만 항목 (방개수, 부엌, 모델링여부 등)이 독립변수로 나오고 집값이 종속변수로 나옴
- 시각화, 전처리, 회귀 모델 평가, 규제, 앙상블 , +a 등 3개의 모델을 Training 시켜 결과를 보는 문제였음


Q2) COVID-19
- 국가별, 일별, 인구수, 확진자수, 사망자수, 완치자수, 검사자수   를 데이터로 줌
- 시각화, 전처리 등은 모델 생성하는게 목표기 때문에 기본으로 깔고 감
- 인구대비 확진자수를 도출해서 (파생 컬럼) Top 5인 국가를 추출 후 시각화 하는 문제 나옴
- 분석가의 역량을 보고자 낸 것 같은데,  확진자수, 사망자수, 인구수, 검사자수, 완치자수 등 변수를 활용하여
'위험지수'라는 파생컬럼을 만들어 보라고 함. 그리고 왜 그렇게 위험지수를 도출했는지 설명,
- Top10 위험지수 국가 시각화
- 시계열 분석해서 '한국' 국가의 확진자수를 예측하는 문제가 나옴
- 시계열 모델뿐만아니라 비시계열 모델로도 모델을 별도 생성 문제 나옴

2.1) 전체 인구대비 코로나 환자가 높은 국가 top10을 뽑아서 시각화.
- 일별 확진자수, 일별 완치자수 코딩 필요
- 데이터셋은 일별 누적확진자 데이터가 나와있음

2.2) 코로나 위험지수를 직접 만들고 그 위험지수에 대한 설명을 적고
위험지수가 높은 국가들 10개를 선정해서 시각화

2.3) 한국의 코로나 확진자 예측 (선형 시계열모델 + 비선형시계열 모델 2개)

Q3) 통계분석 (50점)
데이터셋 : 설문조사 데이터. 이 설문조사 데이터는 기본적으로 묶을 그룹이 2개이다.
A~S까지의 그룹이 각각 같은 설문조사를 하여 
1-1,1-2,1-3...5-1,5-2 인 설문지를 푼 것이다. 
이 때 중간에 반대 문항이 들어가 있다. 
예를 들어 1-1 문제가 나는 시간약속을 잘 지킨다.라는 문제라면 
1-3의 문제는 나는 시간약속을 잘 지키지 않는다. 라는 문제로 구성되어있다.

설문조사 데이터가 문제로 나옴
데이터는 대략
조사 번호, 그룹, 문항1-1 , 1-2, 1-3 .....     6-8  
이런 컬럼을 가진 테이블 데이터를 주고,  문항 컬럼에 들어가는 값들은 만족도 지수를 1~5점척도로 조사를 한 값이었음
1-1~ 1-x 는 항목 1,
2-1 ~ 2-x 는 항목 2
이런식으로 항목 영역이 규정된다고 전제를 함
그리고 역항목이라고 해서 1-1번의 역항목은  1-3 이고..
(설문조사시 동일내용에 대해 서로 긍정/부정 상반되는 문항을 제시해서 신뢰도를 올리기 위한 그런 항목으로 이해를 했다.)

그리고 특정 항목의 
1. 그룹별, 영역별 기술통계량 (평균, 표준편차, 첨도, 왜도)
각 영역별 그룹별 만족도 추세가 어떤지? 탐색
2. 그리고 요인분석
3. 신뢰성 지수라는 걸 구하는 식을 주고 (대략 각 영역별 correlation의 평균과 개수가 필요한 식이었음)
그걸 구하는 문제

3-1) 그룹별 통계치
3-2) 탐색적 요인분석을 표로 만들기
3-3) 기억안남


1. Housing Data(집값 예측)
1-1) EDA 및 데이터 전처리 (시각화 및 통계량 제시)
1-2) Train Valid Test set으로 분할 및 시각화 제시
1-3) 2차 교호작용항 까지 고려한 회귀분석 수행 및 변수 선택 과정 제시
1-4) 벌점, 앙상블을 포함하여 모형에 적합한 기계하습 모델 3가지 (MSE, MAPE, R2 제시)

2. Corona Data(시계열)
2-1) 인구대비 코로나 확진자 비율이 가장 높은 국가 5개 제시하고 일일확진자, 누적확진자, 일일 사망자, 누적 사망자 추이를 각각 1장씩의 시각화 그래프로 시각화(차분을 이용함)
2-2)
2-3) 코로나 위험지수를 개발하고 위험지수가 높은 국가 10개를 추려내서 막대그래프로 시각화하기
2-4) 시계열 모델링 및 비선형 모델링

3. Survey Data
분석 전, 역코딩을 반영해야함.
3-1) 항목별 그룹별 만족도 응답의 평균, 표준편차, 왜도, 첨도를 구하라.
(이렇게보면 별거 아닌거 같지만 실제 데이터를 보면 말이 엄청 애매한 문제입니다)
3-2) 응답항목별 차이가 있는지 분석
(아마 Anova Table을 요구하는 것 같습니다)

3-3) 탐색적 요인분석 수행(FactorAnalysis)
3-4) 신뢰성 지수를 개발 하는 문제 항목별 신뢰성 지수를 구하라.

================================================

[[18회]] 2020.09.19
https://t0-0t.tistory.com/16
https://ckmoong.tistory.com/7?category=933194


크게 3문제

-ARIMA 50점 
차분하는 방법, ACF와 PACF 그래프 보는 방법, 
AR 차수와 MA 차수 정하는 방법 등을 조사. ARIMA

-SOM

1. 기계학습 : 고객 등급(1부터 5까지) 분류 예측 모형
- EDA 및 결측치 처리를 포함하여 데이터 전처리
- 파생변수 3개를 생성하고 생성한 근거를 시각화나 통계량으로 제시
- 데이터를 train_test로 나누고 train에 대해 som을 이용해 군집분석을 실시하고 최적화 수행후 confusion matrix를 그리시오
- 랜덤포레스트, 인공신경망(이부분은 기억이 잘 안나네요ㅜㅜ) 을 포함해 4개의 분류 예측 모형을 만들고 각각의 성능을 roc_auc, F1_score로 비교하시오 
- 앞에서 정한 모델에 추가로 성능을 높이시오

2. 영어 텍스트
- 영어 문장을 의미없는 단어를 없애고 형태소 분석을 하시오
- 단어 빈도를 시각화하시오 (원래는 워드클라우드도 하는 문제인데 시험 도중에 이부분은 빼주었습니다)

3. 통계분석 : 3~4년치 매출데이터(어떤 데이터인지 가물가물합니다)
- 시계열의 정상성을 만족시키시오 
- 모형을 3개 이상 만들어 비교하시오
- 앞에서 정한 모델을 진단(통계적인 진단을 요구했습니다)
- 예측의 정확도를 나타내시오

 - 18회 기출 생각나는 대로-
1) 기계학습 - SOM
데이터파일명 sales.csv
컬럼 : id(고객아이디), ....(기억안남) ,duration, count, amount
1.1) 데이터 전처리, 사유, 시각화
duration, count, amount에 결측치 존재(약 1200건)
amount에는 -존재
1.2) SOM 돌리기
1.3) 나온 모델로 예측

2) 텍스트마이닝
빈출명사를 bar chart로 나타내고, 잘보이도록 시각화
(데이터는 전부 영문이었음)

3) 통계분석 - ARIMA
데이터는 월별교통사고건수.csv
YR_MO : YYYY-MM으로 된 데이터
EVN_CNT : 교통사고 수
3.1) 주기별 평균과 분산의 정상성 검증, 방법, 방법을 선택한 이유, 가능하면 시각화
- 계절로 주기를 만들어 줬었다....
3.2) ARIMA 돌리기
3.3) 해석(OOOO표를 통해서 - 잘 기억 안남)

모든 문항마다 필요하다면 시각화를 하시오.

1. 고객 등급 예측모형
1) EDA & 결측값 채우기
2-1) 파생변수 3개 생성 & 이유 작성
2-2) Train-Test 분할(7:3) / SOM 군집분석 / 정오분류표
2-3) 분류분석 4가지

2. 텍스트 마이닝(영어)
- 명사 추출 & 불용어 처리
- 빈도 막대그래프

3. 시계열분석(데이터구성 : Year/month/amount)
1) 평균과 분산 일정 + 근거 & 해석
2) ARIMA + 근거 & 해석
3) 최적 모델 선택 + 근거 & 해석
4) 적합 파악

- 정상성 확인 (10점)
- ARIMA모델 3가지 제시 (10점)
- 한가지 모델을 최종 선택하고 이유를 서술 (15점)
- 최종 예측을 하고, 실제 결과와 비교 평가하고 그 평가 방법을 사용한 이유를 제시 (15점)


================================================

[[19회]]  2020.12.13
https://evergreentags.tistory.com/17
https://mizykk.tistory.com/127?category=690990

실기 문제
1. 기계학습
1) 전처리 / 탐색적데이터분석(EDA) / 시각화
2) train-test 분리(7:3) / 분류모델 3가지 / Confusion Matrix
3) 분류모델 > 앙상블하여 예측하고 result.csv 제출하기

2. 시계열분석
1) 시계열 시각화 → 이분산성 / 정상성
2) 고정시계열 확인 & 처리
3) SARIMA 분석
4) 잔차/잡음 시각화 & 분석

그러나 SARIMA, 고정시계열은 데이터에듀 책에도 없으면서 나와서.. 조금 당황스러웠다. 데이터에듀 책만으로는 부족하고, 
다른 책이나 자료들을 참고하여 좀 더 브로드하게 준비해야하는 것 같다. 


1. 기계학습(DATA : credit데이터 - 고객이 이탈되었는지 아닌지 분류하는 문제) (총 50점)
- 독립변수로는 성별, 나이, 카드등급, 소득 등의 변수들이 있었습니다.
1-1 : 데이터 전처리 및 시각화(5점) - 연속형변수와 문자로된 범주형 변수를 처리해야합니다.
1-2 : Train과 Test를 7:3으로 나누고 분류분석 3개 실시 및 Confusion Matrix 만들기(15점)
1-3 : 위에서 실시한 분류분석 3개를 앙상블하여 Credit_test를 예측하고(credit_test.csv는 따로 주어짐) result.csv로 만들어서 제출하기(30점)
- 1-1과 1-2는 기존처럼 코드와 해석결과를 PDF로 만들어서 제출하면 되고 1-3은 CSV파일로 제출하면 됩니다.

2. 통계학습(DATA : Traffic EPS 시계열 분석 - 20년치 데이터이며 1년에 4개씩 데이터가 존재(분기별로 존재)) (총 50점)
2-1 시계열 데이터의 정규성과 이분산성을 분석하기 위해 시각화하고 설명(10점)
2-2 위에서 시계열데이터가 정규성이 아니라면, 고정시계열이 있는지 확인하고 이를 처리(15점)
2-3 SARIMA 분석을 실시, 여러 파라미터를 적용해보고 가장 성능이 좋은 것을 제시(15점)
2-4 위에서 제시한 모델의 잔차와 잡음에 대해 시각화하고 분석(10점
